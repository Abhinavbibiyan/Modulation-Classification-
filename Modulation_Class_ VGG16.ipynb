{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"ikrerzEcsTyr"},"outputs":[],"source":["from scipy.io import loadmat\n","from pandas import factorize\n","import pickle\n","import numpy as np\n","import random\n","from scipy import signal\n","from matplotlib import pyplot as plt\n","from sklearn.metrics import confusion_matrix\n","import seaborn as sns\n","from tensorflow.keras.utils import to_categorical\n","import tensorflow as tf\n","from tensorflow import keras\n","from tensorflow.keras import backend as K\n","from tensorflow.keras import layers\n","from tensorflow.keras.utils import plot_model\n","import os,random\n","os.environ[\"KERAS_BACKEND\"] = \"tensorflow\"\n","import math\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import pickle, random, sys, keras\n","\n","import keras.models as models\n","\n","from keras.layers import Input,Conv2D, Dense, MaxPool2D, Flatten,ZeroPadding1D,MaxPool1D\n","from keras.layers import Conv2D, MaxPooling2D, AveragePooling2D,ZeroPadding2D\n","from keras.layers import Reshape, Dense, Dropout, Activation\n","\n","from keras.layers import  ZeroPadding1D, MaxPool1D\n","from keras.regularizers import *\n","from tensorflow.keras.optimizers import Adam\n","from keras.layers import Dense, Conv2D, MaxPool2D , Flatten"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"DV1rHte-slVI"},"outputs":[],"source":["# RadioML2016.10a/10b or MIGOU MOD\n","\n","def load_dataset(dataset_location):\n","    \"\"\"\n","    Load dataset and extract needed data\n","\n","    Input:\n","        dataset_location: specify where the file is stored and its name\n","\n","    Output:\n","        snrs: list of the SNR range in dataset [-20 to 18]\n","        X: array of the measured I/Q data [num_of_samples, 128, 2]\n","        modulations: list of the modulations in this dataset\n","        one_hot_encode: one_hot encoded data - the other maps the order of the mods\n","        lbl_SNR: list of each snr (for plotting)\n","    \"\"\"\n","\n","    snrs,mods = map(lambda j: sorted(list(set(map(lambda x: x[j], dataset_location.keys())))), [1,0])\n","\n","    X = []; I = []; Q = []; lbl = [];\n","\n","    for mod in mods:\n","        for snr in snrs:\n","            X.append(dataset_location[(mod,snr)])\n","            for i in range(dataset_location[(mod,snr)].shape[0]):\n","                lbl.append((mod,snr))\n","    X = np.vstack(X); lbl=np.vstack(lbl)\n","\n","    X = np.transpose(X[:,:,:],(0,2,1))\n","\n","    # One-hot-encoding\n","    Y = [];\n","    for i in range(len(lbl)):\n","        mod = (lbl[i,0])\n","        Y.append(mod)\n","\n","    mapping = {}\n","    for x in range(len(mods)):\n","        mapping[mods[x]] = x\n","\n","    ## integer representation\n","    for x in range(len(Y)):\n","        Y[x] = mapping[Y[x]]\n","\n","    one_hot_encode = to_categorical(Y)\n","\n","    # Assign SNR value to each vector\n","    repeat_n = X.shape[0]/len(mods)/len(snrs)\n","    repeat_n_mod = len(mods)\n","    lbl_SNR = np.tile(np.repeat(snrs, repeat_n), repeat_n_mod)\n","\n","\n","\n","    return snrs, X, mods, one_hot_encode, lbl_SNR"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_EGye9NqbISm"},"outputs":[],"source":["#X.shape\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_tdu9Lduswjo"},"outputs":[],"source":["# RML2016.10b / just for the way it is saved in my GoogleDrive\n","\n","def load_RMLb_dataset(X, lbl):\n","    mods = np.unique(lbl[:,0])\n","    snrs = np.unique(lbl[:,1])\n","    snrs = list(map(int, snrs))\n","    snrs.sort()\n","\n","    # One-hot encoding\n","    Y = [];\n","    for i in range(len(lbl)):\n","        mod = (lbl[i,0])\n","        Y.append(mod)\n","\n","    mapping = {}\n","    for x in range(len(mods)):\n","        mapping[mods[x]] = x\n","\n","    ## integer representation\n","    for x in range(len(Y)):\n","        Y[x] = mapping[Y[x]]\n","\n","    one_hot_encode = to_categorical(Y)\n","\n","\n","    # Assign SNR value to each vector\n","    repeat_n = X.shape[0]/len(mods)/len(snrs)\n","    repeat_n_mod = len(mods)\n","    lbl_SNR = np.tile(np.repeat(snrs, repeat_n), repeat_n_mod)\n","\n","    X = X\n","\n","    return snrs, X, mods, one_hot_encode, lbl_SNR\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZP_EopLRs0hT"},"outputs":[],"source":["def train_test_valid_split(X, one_hot, train_split=0.7, valid_split=0.15, test_split=0.15):\n","\n","    \"\"\"\n","    Train-Test split the data\n","\n","    Input:\n","        X: X data\n","        one_hot: Y data encoded to one_hot\n","        train_split (default 0.7)\n","        valid_split (default 0.15)\n","        test_split (default 0.15)\n","        train_split : valid_split : test_split - ratio for splitting the dataset\n","\n","        NOTE: the ratio split must be a sum of 1!\n","\n","    Output:\n","        train_idx: indexes from X assinged to train data\n","        valid_idx: indexes from X assinged to validation data\n","        test_idx: indexes from X assinged to test data\n","        X_train: X data assigned for training\n","        X_valid: X data assigned for validation\n","        X_test: X data assigned for testing\n","        Y_train: one-hot encoded Y data assigned for training\n","        Y_valid: one-hot encoded Y data assigned for validation\n","        Y_test: one-hot encoded Y data assigned for testing\n","    \"\"\"\n","\n","    # Set random seed\n","    np.random.seed(42)\n","    random.seed(42)\n","\n","    # Get the number of samples\n","    n_examples = X.shape[0]\n","    n_train = int(n_examples * train_split)\n","    n_valid = int(n_examples * valid_split)\n","    n_test = int(n_examples * test_split)\n","\n","    # Get indexes of train data\n","    train_idx = np.random.choice(range(0, n_examples), size=n_train, replace=False)\n","\n","    # Left indexes for valid and test sets\n","    left_idx= list(set(range(0, n_examples)) - set(train_idx))\n","\n","    # Get indexes for the left indexes of the X data\n","    val = np.random.choice(range(0, (n_valid+n_test)), size=(n_valid), replace=False)\n","    test = list(set(range(0, len(left_idx))) - set(val))\n","\n","    # Assign indeces for validation to left indexes\n","    valid_idx = []\n","    for i in val:\n","        val_idx = left_idx[i]\n","        valid_idx.append(val_idx)\n","\n","    # Get the test set as the rest indexes\n","    test_idx = []\n","    for i in test:\n","        tst_idx = left_idx[i]\n","        test_idx.append(tst_idx)\n","\n","    # Shuffle the valid_idx and test_idx\n","    random.shuffle(valid_idx)\n","    random.shuffle(test_idx)\n","\n","    # Assing the indexes to the X and Y data to create train and test sets\n","    X_train = X[train_idx]\n","    X_valid = X[valid_idx]\n","    X_test = X[test_idx]\n","    Y_train = one_hot[train_idx]\n","    Y_valid = one_hot[valid_idx]\n","    Y_test = one_hot[test_idx]\n","\n","    return train_idx, valid_idx, test_idx, X_train, X_valid, X_test, Y_train, Y_valid, Y_test\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"j97n85Uks3pL"},"outputs":[],"source":["def normalize_data(X_train, X_valid, X_test):\n","        # mean-std normalization\n","\n","    mean = X_train[:,:,:].mean(axis=0)\n","    X_train[:,:,:] -= mean\n","    std = X_train[:,:,:].std(axis=0)\n","    X_train[:,:,:] /= std\n","\n","\n","    X_valid[:,:,:] -= mean\n","    X_valid[:,:,:] /= std\n","\n","    X_test[:,:,:] -= mean\n","    X_test[:,:,:] /= std\n","\n","    return X_train, X_valid, X_test"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"l3c8UWNps6it"},"outputs":[],"source":["def return_indices_of_a(a, b):\n","    \"\"\"\n","    Compare two lists a, b for same items and return indeces\n","    of the item in list a\n","\n","    a:    List of items, its indeces will be returned\n","    b:    List of items to search for in list a\n","\n","    Credit: https://stackoverflow.com/users/97248/pts ; https://stackoverflow.com/questions/10367020/compare-two-lists-in-python-and-return-indices-of-matched-values\n","    \"\"\"\n","    b_set = set(b)\n","    return [i for i, v in enumerate(a) if v in b_set]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ClJfBu7Ys-RH"},"outputs":[],"source":["def show_confusion_matrix(validations, predictions, matrix_snr, save=True):\n","    \"\"\"\n","    Plot confusion matrix\n","\n","    validations:    True Y labels\n","    predictions:    Predicted Y labels of your model\n","    matrix_snr:     SNR information for plot's titel\n","    \"\"\"\n","\n","    cm = confusion_matrix(validations, predictions)\n","    # Normalise\n","    cmn = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n","    fig, ax = plt.subplots(figsize=(10,10))\n","    sns.heatmap(cmn, cmap='Blues', annot=True, fmt='.2f', xticklabels=mods, yticklabels=mods)\n","    sns.set(font_scale=1.3)\n","    if matrix_snr == None:\n","        plt.title(\"Confusion Matrix\")\n","    else:\n","        plt.title(\"Confusion Matrix \\n\" + str(matrix_snr) + \"dB\")\n","    plt.ylabel('True Label')\n","    plt.xlabel('Predicted Label')\n","    if save == True:\n","        plt.savefig('VGGMatrix.png',dpi=300)\n","\n","    plt.show(block=True)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mx1CrGlUtBSz"},"outputs":[],"source":["def All_SNR_show_confusion_matrix(X_test, save=True):\n","    \"\"\"\n","    Plot confusion matrix of all SNRs in one\n","\n","    X_test:   X_test data\n","    \"\"\"\n","    prediction = model.predict(X_test)\n","\n","    Y_Pred = []; Y_Test = [];\n","\n","    for i in range(len(prediction[:,0])):\n","        Y_Pred.append(np.argmax(prediction[i,:]))\n","        Y_Test.append(np.argmax(Y_test[i]))\n","\n","    show_confusion_matrix(Y_Pred, Y_Test, None, save)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"U-W7tReftEkE"},"outputs":[],"source":["def SNR_show_confusion_matrix(in_snr, lbl_SNR, X_test, save=True):\n","    \"\"\"\n","    Plot confusion matrices of chosen SNRs\n","\n","    in_snr:   must be list of SNRs\n","    X_test:   X_test data\n","    \"\"\"\n","    for snr in in_snr:\n","        matrix_snr = snr\n","        m_snr = matrix_snr;\n","\n","        Y_Pred = []; Y_Test = []; Y_Pred_SNR = []; Y_Test_SNR = [];\n","        matrix_snr_index = [];\n","\n","        prediction = model.predict(X_test)\n","\n","        for i in range(len(prediction[:,0])):\n","            Y_Pred.append(np.argmax(prediction[i,:]))\n","            Y_Test.append(np.argmax(Y_test[i]))\n","\n","        for i in range(len(lbl_SNR)):\n","            if int(lbl_SNR[i]) == m_snr:\n","                matrix_snr_index.append(i)\n","\n","        indeces_of_Y_test = return_indices_of_a(test_idx, matrix_snr_index)\n","\n","        for i in indeces_of_Y_test:\n","            Y_Pred_SNR.append(Y_Pred[i])\n","            Y_Test_SNR.append(Y_Test[i])\n","        show_confusion_matrix(Y_Pred_SNR, Y_Test_SNR, matrix_snr, save)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"MWRlGmjetLYa"},"outputs":[],"source":["def plot_split_distribution(mods, Y_train, Y_valid, Y_test):\n","\n","    x = np.arange(len(mods))  # the label locations\n","    width = 1  # the width of the bars\n","\n","    fig, ax = plt.subplots()\n","    bar1 = ax.bar(x-width*0.3, np.count_nonzero(Y_train == 1, axis=0), width*0.3, label = \"Train\" )\n","    bar2 = ax.bar(x , np.count_nonzero(Y_valid == 1, axis=0), width*0.3, label = \"Valid\" )\n","    bar3 = ax.bar(x+width*0.3, np.count_nonzero(Y_test == 1, axis=0), width*0.3, label = \"Test\" )\n","\n","\n","    # Add some text for labels, title and custom x-axis tick labels, etc.\n","    ax.set_ylabel('Distribution')\n","    ax.set_title('Distribution overview of splitted dataset')\n","    ax.set_xticks(x)\n","    ax.set_xticklabels(mods)\n","    ax.legend(loc='upper center', bbox_to_anchor=(0.5, -0.15),\n","            fancybox=True, shadow=True, ncol=5)\n","\n","\n","    def autolabel(rects):\n","        \"\"\"Attach a text label above each bar in *rects*, displaying its height.\"\"\"\n","        for rect in rects:\n","            height = rect.get_height()\n","            ax.annotate('{}'.format(height),\n","                        xy=(rect.get_x() + rect.get_width() / 2, height),\n","                        xytext=(0, 0),  # 3 points vertical offset\n","                        textcoords=\"offset points\",\n","                        ha='center', va='bottom')\n","\n","    # autolabel(bar1)\n","    # autolabel(bar2)\n","    # autolabel(bar3)\n","    # fig.tight_layout()\n","    return plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"I44oQFAutPRm"},"outputs":[],"source":["def SNR_accuracy(in_snr, name):\n","    \"\"\"\n","    Computes accuracies of chosen SNRs individualy\n","\n","    in_snr:   must be list of SNRs\n","    \"\"\"\n","\n","    acc = []\n","    for snr in in_snr:\n","        acc_snr = snr\n","        idx_acc_snr = []\n","\n","        for i in range(len(test_idx)):\n","            if int(lbl_SNR[test_idx[i]]) == int(acc_snr):\n","                idx_acc_snr.append(i)\n","\n","        acc_X_test = X_test[idx_acc_snr]\n","        # acc_X_f_test = X_f_test[idx_acc_snr]\n","        acc_Y_test = Y_test[idx_acc_snr]\n","\n","        print('\\nSNR ' + str(acc_snr) + 'dB:')\n","        accuracy_snr = model.evaluate([acc_X_test], acc_Y_test, batch_size=32, verbose=2)\n","        acc.append(accuracy_snr)\n","\n","    acc = np.vstack(acc)\n","    fig = plt.figure()\n","    ax = fig.add_subplot(1, 1, 1)\n","    plt.plot(SNR, (acc[:,1]*100), marker='.', markersize= 10, label = name, linestyle = '-',)\n","    ax.legend(loc=4, prop={'size': 15})\n","\n","    x_major_ticks = np.arange(-20, 19, 2 )\n","    ax.set_xticks(x_major_ticks)\n","\n","    y_major_ticks = np.arange(0, 101, 10 )\n","    y_minor_ticks = np.arange(0, 101, 2)\n","    ax.set_yticks(y_major_ticks)\n","    ax.set_yticks(y_minor_ticks, minor=True)\n","    ax.tick_params(axis='both', which='major', labelsize=10)\n","\n","    ax.grid(which='both', linestyle='-')\n","\n","    ax.grid(which='minor', alpha=0.2)\n","    ax.grid(which='major', alpha=0.5)\n","\n","    plt.xlim(-20, 18)\n","    plt.ylim(0,100)\n","    plt.title(\"Classification Accuracy\",fontsize=10)\n","    plt.ylabel('Accuracy (%)',fontsize=10)\n","    plt.xlabel('SNR (dB)',fontsize=10)\n","#     plt.savefig(base_dir + name + '.png')\n","    plt.savefig(\"VGG.png\",dpi=300)\n","#     files.download(\"VGG.png\")\n","    plt.show()\n","\n","    return acc[:,1]\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8L2KuvqNtSDC"},"outputs":[],"source":["def layer_overview(model):\n","\n","    \"\"\"\n","    Offers overview of the model's layers and theirs outputs\n","\n","    model: specify trained model you want to have overview of\n","    \"\"\"\n","\n","    # Names and outputs from layers\n","    layer_names = [layer.name for layer in model.layers]\n","    layer_outputs = [layer.output for layer in model.layers[:]]\n","\n","    return layer_names, layer_outputs\n","\n","def model_visualization(nth_layer, nth_test_idx, mods, model,\n","                        plot_sample = False, plot_activations = True,\n","                        plot_feature_maps = True):\n","\n","    \"\"\"\n","    The function provised overview of activation of specific layer and its\n","    feature maps.\n","\n","    nth_layer: enter number which corresponds with the position of wanted layer\n","    nth_test_idx: enter number pointing at the test indexes from earlier\n","    mods: provide variable which holds listed modulations\n","    model: specify which trained model to load\n","    plot_sample = False: set to true to plot sample data\n","    plot_activations = True: plots activation of chosen layer\n","    plot_feature_maps = True: plots feature map of chosen layer\n","    \"\"\"\n","\n","    # Sample data for visualization\n","    test_sample = X_test[nth_test_idx,:,:] # shape [128,2]\n","    test_sample = test_sample[None] # change to needed [1,128,2]\n","    SNR = lbl_SNR[test_idx[nth_test_idx]]\n","    mod = one_hot[test_idx[nth_test_idx]]\n","    f, u = factorize(mods)\n","    mod = mod.dot(u)\n","\n","    # Names and outputs from layers\n","    layer_names = [layer.name for layer in model.layers]\n","    layer_outputs = [layer.output for layer in model.layers[:]]\n","\n","    ## Activations ##\n","\n","    # define activation model\n","    activation_model = tf.keras.models.Model(model.input, layer_outputs)\n","\n","    # get the activations of chosen test sample\n","    activations = activation_model.predict(test_sample)\n","\n","    ## Feature-maps ##\n","\n","    # define feature maps model\n","    feature_maps_model = tf.keras.models.Model(model.inputs, model.layers[4].output)\n","\n","    # get the activated features\n","    feature_maps = feature_maps_model.predict(test_sample)\n","\n","\n","    # Plot sample\n","    if plot_sample == True:\n","        plt.plot(test_sample[0,:,:])\n","        plt.title(mod + '    ' + str(SNR) + 'dB')\n","        plt.show()\n","\n","    # Plot activations\n","    if plot_activations == True:\n","        activation_layer = activations[nth_layer]\n","        activation_layer = np.transpose(activation_layer[:,:,:],(0,2,1)) # reshape\n","        fig, ax = plt.subplots(figsize=(20,10))\n","        ax.matshow(activation_layer[0,:,:],  cmap='viridis')\n","        # plt.matshow(activation_layer[0,:,:],  cmap='viridis')\n","        plt.title('Activation of layer ' + layer_names[nth_layer])\n","        ax.grid(False)\n","        ax.set_xlabel('Lenght of sequence')\n","        ax.set_ylabel('Filters')\n","        fig.show()\n","\n","\n","    # Plot feature maps\n","    if plot_feature_maps == True:\n","        n_filters = int(feature_maps.shape[2]/2); ix = 1\n","        fig = plt.figure(figsize=(25,15))\n","        for _ in range(n_filters):\n","            for _ in range(2):\n","                # specify subplot and turn of axis\n","                ax =fig.add_subplot(n_filters,  5, ix)\n","                # ax = plt.subplot(n_filters,  5, ix, )\n","                ax.set_xticks([])\n","                ax.set_yticks([])\n","                # plot filter channel in grayscale\n","                ax.plot(feature_maps[0, :, ix-1])\n","                ix += 1\n","        # show the figure\n","        fig.show()\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_pB7-c0S_qsu"},"outputs":[],"source":["def merge_dict(dict1,dict2):\n","  return(dict2.update(dict1))"]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8yrtFf0UbZ-i","outputId":"d37ab95c-d4cc-40cf-c04f-2994647f070e","executionInfo":{"status":"ok","timestamp":1699289890060,"user_tz":-330,"elapsed":3782,"user":{"displayName":"ABHINAV","userId":"09359026150255159356"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2Nk1UI6ttVYW","outputId":"c13d9d6a-d44a-4dc9-9787-1d6f70fefedb","executionInfo":{"status":"ok","timestamp":1699289918982,"user_tz":-330,"elapsed":28932,"user":{"displayName":"ABHINAV","userId":"09359026150255159356"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["[('PAM4', -20), ('PAM4', -18), ('PAM4', -16), ('PAM4', -14), ('PAM4', -12), ('PAM4', -10), ('PAM4', -8), ('PAM4', -6), ('PAM4', -4), ('PAM4', -2), ('PAM4', 0), ('PAM4', 2), ('PAM4', 4), ('PAM4', 6), ('PAM4', 8), ('PAM4', 10), ('PAM4', 12), ('PAM4', 14), ('PAM4', 16), ('PAM4', 18), ('QAM16', -20), ('QAM16', -18), ('QAM16', -16), ('QAM16', -14), ('QAM16', -12), ('QAM16', -10), ('QAM16', -8), ('QAM16', -6), ('QAM16', -4), ('QAM16', -2), ('QAM16', 0), ('QAM16', 2), ('QAM16', 4), ('QAM16', 6), ('QAM16', 8), ('QAM16', 10), ('QAM16', 12), ('QAM16', 14), ('QAM16', 16), ('QAM16', 18), ('QAM64', -20), ('QAM64', -18), ('QAM64', -16), ('QAM64', -14), ('QAM64', -12), ('QAM64', -10), ('QAM64', -8), ('QAM64', -6), ('QAM64', -4), ('QAM64', -2), ('QAM64', 0), ('QAM64', 2), ('QAM64', 4), ('QAM64', 6), ('QAM64', 8), ('QAM64', 10), ('QAM64', 12), ('QAM64', 14), ('QAM64', 16), ('QAM64', 18), ('QPSK', -20), ('QPSK', -18), ('QPSK', -16), ('QPSK', -14), ('QPSK', -12), ('QPSK', -10), ('QPSK', -8), ('QPSK', -6), ('QPSK', -4), ('QPSK', -2), ('QPSK', 0), ('QPSK', 2), ('QPSK', 4), ('QPSK', 6), ('QPSK', 8), ('QPSK', 10), ('QPSK', 12), ('QPSK', 14), ('QPSK', 16), ('QPSK', 18), ('8PSK', -20), ('8PSK', -18), ('8PSK', -16), ('8PSK', -14), ('8PSK', -12), ('8PSK', -10), ('8PSK', -8), ('8PSK', -6), ('8PSK', -4), ('8PSK', -2), ('8PSK', 0), ('8PSK', 2), ('8PSK', 4), ('8PSK', 6), ('8PSK', 8), ('8PSK', 10), ('8PSK', 12), ('8PSK', 14), ('8PSK', 16), ('8PSK', 18), ('BPSK', -20), ('BPSK', -18), ('BPSK', -16), ('BPSK', -14), ('BPSK', -12), ('BPSK', -10), ('BPSK', -8), ('BPSK', -6), ('BPSK', -4), ('BPSK', -2), ('BPSK', 0), ('BPSK', 2), ('BPSK', 4), ('BPSK', 6), ('BPSK', 8), ('BPSK', 10), ('BPSK', 12), ('BPSK', 14), ('BPSK', 16), ('BPSK', 18)]\n"]}],"source":["# with open('/content/drive/MyDrive/Colab Notebooks/RML2016.10b.dat', 'rb') as f:\n","with open('/content/drive/MyDrive/Colab Notebooks/RML2016.10b/RML2016.10b.dat', 'rb') as f:\n","    Xd = pickle.load(f, encoding='latin1')\n","sorted_data = {k: Xd[k] for k in sorted(Xd.keys())[0:200]}\n","data1={k: Xd[k] for k in sorted(sorted_data.keys())[0:20]}\n","data2={k: Xd[k] for k in sorted(sorted_data.keys())[40:60]}\n","merge_dict(data2,data1)\n","data={k: Xd[k] for k in sorted(sorted_data.keys())[100:180]}\n","merge_dict(data1,data)\n","#print(data)\n","print(list(data.keys()))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hkrfcGp5tf7K"},"outputs":[],"source":["# 10a\n","SNR, X, modulations, one_hot, lbl_SNR = load_dataset(data)\n","# 10b\n","# SNR, X, modulations, one_hot, lbl_SNR = load_RMLb_dataset(RMLb_X, RMLb_lbl)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ync8byUry_Cl","outputId":"93b3f06c-da83-4648-8018-bff70cf1a7fb","executionInfo":{"status":"ok","timestamp":1699289922215,"user_tz":-330,"elapsed":422,"user":{"displayName":"ABHINAV","userId":"09359026150255159356"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["['8PSK', 'BPSK', 'PAM4', 'QAM16', 'QAM64', 'QPSK']\n"]}],"source":["# with open('/content/drive/MyDrive/Colab Notebooks/RML2016.10b/RML2016.10b.dat', 'rb') as f:\n","# # with open('/content/drive/MyDrive/Colab Notebooks/RML2016.10a/RML2016.10a_dict.pkl', 'rb') as f:\n","#     Xd = pickle.load(f, encoding='latin1')\n","snrs,mods = map(lambda j: sorted(list(set(map(lambda x: x[j], data.keys())))), [1,0])\n","# unwanted = ['8PSK', 'WBFM', 'CPFSK', 'GFSK','AM-DSB']\n","# mods=set(mods).difference(set(unwanted))\n","# mods=list(mods)\n","print(mods)\n","X = []\n","lbl = []\n","for mod in mods:\n","    for snr in snrs:\n","        X.append(data[(mod,snr)])\n","        for i in range(data[(mod,snr)].shape[0]):\n","            lbl.append((mod,snr))\n","\n","X = np.vstack(X)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"PVp10hocjcAB"},"outputs":[],"source":["# unwanted = ['8PSK', 'WBFM', 'CPFSK', 'GFSK','AM-DSB']\n","# mods=set(mods).difference(set(unwanted))\n","# list(mods)\n","# print(mods)\n","# SNR, X, modulations, one_hot, lbl_SNR = load_dataset(Xd)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZFbDRlfEy1S-"},"outputs":[],"source":["def to_onehot(yy):\n","\n","    data = list(yy)\n","    yy1 = np.zeros([len(data), max(data)+1])\n","    yy1[np.arange(len(data)),data]=1\n","\n","    return yy1"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nY4BlSuvyvnZ"},"outputs":[],"source":["# np.random.seed(2017)\n","# n_examples = X.shape[0]\n","# n_train = int(n_examples * 0.7)\n","# train_idx = np.random.choice(range(0,n_examples), size=n_train, replace=False)\n","# test_idx = list(set(range(0,n_examples))-set(train_idx))\n","# X_train = X[train_idx]\n","# X_test =  X[test_idx]\n","# Y_train = to_onehot(map(lambda x: mods.index(lbl[x][0]), train_idx))\n","# Y_test = to_onehot(map(lambda x: mods.index(lbl[x][0]), test_idx))\n","# in_shp = list(X_train.shape[1:])\n","# classes = mods"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"DMeO1dZOtpLE"},"outputs":[],"source":["train_idx, valid_idx, test_idx, X_train, X_valid, X_test, Y_train, Y_valid, Y_test = train_test_valid_split(X, one_hot, train_split=0.8, valid_split=0.1, test_split=0.1)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Y9td-H-Et8iI"},"outputs":[],"source":["X_train, X_valid, X_test = normalize_data(X_train, X_valid, X_test)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xFpaXaHdxh7h"},"outputs":[],"source":["# Set up some params\n","#nb_epoch =   45   # number of epochs to train on\n","#batch_size = 1024  # training batch size\n","#dr = 0.3 # dropout rate (%)#"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9Urinjl9yW9w"},"outputs":[],"source":["# in_shp = list(X_train.shape[1:])\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zPx97tIEt-3o"},"outputs":[],"source":["def resnet_model(in_shp):\n","    # Input layer\n","    # Reshape(in_shp+[1], input_shape=in_shp)\n","    inputs = tf.keras.Input(shape=in_shp)\n","    # Convolutional block 1\n","    x = layers.Conv2D(64, kernel_size=(3, 3), padding='same', activation='relu')(inputs,inputs)\n","    x = layers.Conv2D(64, kernel_size=(3, 3), padding='same', activation='relu')(x)\n","    x = layers.MaxPooling2D(pool_size=(2, 2))(x)\n","    x = layers.BatchNormalization()(x)\n","    # Residual blocks\n","    num_blocks = 4  # Number of residual blocks\n","    num_filters = 64  # Number of filters in each residual block\n","    for _ in range(num_blocks):\n","        # Residual connection\n","        residual = x\n","        # Convolutional block\n","        x = layers.Conv2D(num_filters, kernel_size=(3, 3), padding='same', activation='relu')(x)\n","        x = layers.Conv2D(num_filters, kernel_size=(3, 3), padding='same', activation='relu')(x)\n","        x = layers.BatchNormalization()(x)\n","        # Skip connection\n","        x = layers.add([x, residual])\n","        x = layers.Activation('relu')(x)\n","    # Global average pooling\n","    x = layers.GlobalAveragePooling2D()(x)\n","    # Fully connected layers\n","    x = layers.Dense(256, activation='relu')(x)\n","    x = layers.Dropout(0.2)(x)\n","    x = layers.Dense(10, activation='softmax')(x)\n","    # Create the model\n","    model = tf.keras.Model(inputs=inputs, outputs=x)\n","    return model"]},{"cell_type":"code","source":["callbacks = [\n","    keras.callbacks.ModelCheckpoint(\n","        \"model.h5\", save_best_only=True, monitor=\"val_loss\"),\n","    keras.callbacks.ReduceLROnPlateau(\n","        monitor=\"val_loss\", factor=0.3, patience=3, min_lr=0.00007),\n","    keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=10, verbose=1)]\n","\n","optimizer = keras.optimizers.Adam(learning_rate=0.0007)\n","# input_shape=(128,2,1)\n","in_shp = list(X_train.shape[:])\n","print(in_shp)\n","# num_classes=10\n","modelsa=resnet_model(in_shp)\n","modelsa.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])"],"metadata":{"id":"AAujq5E18mqF","colab":{"base_uri":"https://localhost:8080/","height":390},"executionInfo":{"status":"error","timestamp":1699289926443,"user_tz":-330,"elapsed":34,"user":{"displayName":"ABHINAV","userId":"09359026150255159356"}},"outputId":"9e1ad201-8941-4c27-d0cc-1037026413a5"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[576000, 2, 128]\n"]},{"output_type":"error","ename":"TypeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-82-080262f6a6f1>\u001b[0m in \u001b[0;36m<cell line: 13>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0min_shp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;31m# num_classes=10\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mmodelsa\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresnet_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0min_shp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0mmodelsa\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'categorical_crossentropy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-81-ed00b2cc0474>\u001b[0m in \u001b[0;36mresnet_model\u001b[0;34m(in_shp)\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0min_shp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;31m# Convolutional block 1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mConv2D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'same'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'relu'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mConv2D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'same'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'relu'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMaxPooling2D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpool_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36m_call_unconverted\u001b[0;34m(f, args, kwargs, options, update_cache)\u001b[0m\n\u001b[1;32m    457\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    458\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 459\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    460\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    461\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mTypeError\u001b[0m: Conv.call() takes 2 positional arguments but 3 were given"]}]},{"cell_type":"code","source":["modelsa.summary()"],"metadata":{"id":"bySjv7JF8qZ6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["tf.keras.backend.clear_session()\n","history = modelsa.fit(X_train, Y_train, batch_size=128, epochs=30, verbose=2, validation_data= (X_valid, Y_valid), callbacks=callbacks)"],"metadata":{"id":"hzOhRDde8uAD"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Wu9WX_RxbISy"},"outputs":[],"source":["# layer_overview(model)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"pwp4Fj2AuT2P","scrolled":true},"outputs":[],"source":["filepath = 'weight_4layers.wts.h5'\n","history = model.fit(X_train,Y_train,batch_size=batch_size,\n","    epochs=nb_epoch,\n","    verbose=1,\n","    validation_data=(X_test, Y_test),\n","    callbacks = [\n","        keras.callbacks.ModelCheckpoint(filepath, monitor='val_loss', verbose=0, save_best_only=True, mode='auto'),\n","        # keras.callbacks.EarlyStopping(monitor='val_loss', patience=5, verbose=0, mode='auto')\n","    ])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"T0PI48UzynaM"},"outputs":[],"source":["model = keras.models.load_model(\"model.h5\")\n","\n","test_loss, test_acc = model.evaluate(X_test, Y_test)\n","\n","print(\"Test accuracy\", test_acc)\n","print(\"Test loss\", test_loss)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Z_29TqoYysyd"},"outputs":[],"source":["SNR_accuracy(SNR, 'ResNet')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"BN5hfDMqytLY"},"outputs":[],"source":["All_SNR_show_confusion_matrix([X_test], save=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"a9Dz2vHIbISz"},"outputs":[],"source":["count=-20"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Kghm5D6QHiKj"},"outputs":[],"source":["def plot_confusion_matrix(cm, title='Confusion matrix', cmap=plt.cm.Blues, labels=True, annot=False, font_size=10,count=0):\n","    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n","    plt.title(title, fontsize=font_size+2)\n","    plt.colorbar()\n","    tick_marks = np.arange(len(labels))\n","    plt.xticks(tick_marks, labels, rotation=45, fontsize=font_size)\n","    plt.yticks(tick_marks, labels, fontsize=font_size)\n","    if annot:\n","        for i in range(cm.shape[0]):\n","            for j in range(cm.shape[1]):\n","                plt.text(j, i, format(cm[i, j], '.2f'),\n","                         horizontalalignment=\"center\",\n","                         color=\"white\" if cm[i, j] > cm.max() / 2. else \"black\",\n","                         fontsize=font_size)\n","\n","    plt.tight_layout()\n","    plt.ylabel('True label', fontsize=font_size)\n","    plt.xlabel('Predicted label', fontsize=font_size)\n","    path=\"VGG-SNR \"+ str(count)+\".png\"\n","    plt.savefig(path,dpi=300)\n","    plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"LZVMgdIwz6bx"},"outputs":[],"source":["acc = {mod: {} for mod in mods}\n","for snr in snrs:\n","  # extract classes @ SNR\n","  test_SNRs = map(lambda x: lbl[x][1], test_idx)\n","  test_SNRs = list(test_SNRs)\n","  test_X_i = X_test[np.where(np.array(test_SNRs)==snr)]\n","  test_Y_i = Y_test[np.where(np.array(test_SNRs)==snr)]\n","\n","  # estimate classes\n","  #tf.config.run_functions_eagerly(True)\n","  test_Y_i_hat = model.predict(test_X_i)\n","  conf = np.zeros([len(classes),len(classes)])\n","  confnorm = np.zeros([len(classes),len(classes)])\n","\n","  for i in range(0,test_X_i.shape[0]):\n","    j = list(test_Y_i[i,:]).index(1)\n","    k = int(np.argmax(test_Y_i_hat[i,:]))\n","    conf[j,k] = conf[j,k] + 1\n","\n","  for i in range(0,len(classes)):\n","    confnorm[i,:] = conf[i,:] / np.sum(conf[i,:])\n","\n","  acc_class = np.diag(confnorm)\n","  print(acc_class)\n","  plt.figure()\n","  plot_confusion_matrix(confnorm, labels=classes, title=\"Confusion Matrix (SNR=%d)\"%(snr), annot=True,font_size=10, count=count)\n","  count+=2\n","  cor = np.sum(np.diag(conf))\n","  ncor = np.sum(conf) - cor\n","  print (\"SNR: \",snr, \" Overall Accuracy: \", cor / (cor + ncor))\n","  acc[snr] = 1.0 * cor / (cor + ncor)\n","#   for mod in mods:\n","#     acc[mod][snr] = 1.0 * cor / (cor + ncor)\n","#   plt.figure(figsize=(4, 4))\n","# # Loop through each modulation and plot\n","#   for mod in mods:\n","#       snrs_values = sorted(list(acc[mod].keys()))\n","#       accuracy_values = [acc[mod][snr] for snr in snrs_values]\n","#       plt.plot(snrs_values, accuracy_values, marker='o', label=mod)\n","\n","#   plt.xlabel('SNR')\n","#   plt.ylabel('Accuracy')\n","#   plt.title('Accuracy for Different Modulations Across SNR values')\n","#   # plt.legend(loc='upper left')\n","#   plt.grid(True)\n","#   plt.show()\n"]},{"cell_type":"code","source":["# Dictionary to store accuracy for each modulation at each SNR\n","mod_acc = {}\n","for mod in mods:\n","    mod_acc[mod] = {}\n","\n","for snr in snrs:\n","    test_SNRs = list(map(lambda x: lbl[x][1], test_idx))\n","    test_X_i = X_test[np.where(np.array(test_SNRs)==snr)]\n","    test_Y_i = Y_test[np.where(np.array(test_SNRs)==snr)]\n","\n","    # estimate classes\n","    test_Y_i_hat = model.predict(test_X_i)\n","    conf = np.zeros([len(classes),len(classes)])\n","\n","    for i in range(0,test_X_i.shape[0]):\n","        j = list(test_Y_i[i,:]).index(1)\n","        k = int(np.argmax(test_Y_i_hat[i,:]))\n","        conf[j,k] = conf[j,k] + 1\n","\n","    # Normalizing the confusion matrix\n","    confnorm = np.zeros([len(classes), len(classes)])\n","    for i in range(0,len(classes)):\n","        confnorm[i,:] = conf[i,:] / np.sum(conf[i,:])\n","\n","    # Saving accuracy for each modulation\n","    for idx, mod in enumerate(mods):\n","        mod_acc[mod][snr] = confnorm[idx, idx]\n","\n","# Plotting\n","plt.figure(figsize=(10,8))\n","for mod in mods:\n","    snrs_values = sorted(list(mod_acc[mod].keys()))\n","    accuracy_values = [mod_acc[mod][snr] for snr in snrs_values]\n","    plt.plot(snrs_values, accuracy_values, marker='o', label=mod)\n","\n","# Set titles, labels, and legends\n","plt.xlabel('SNR')\n","plt.ylabel('Accuracy')\n","plt.title('Modulation Specific Accuracy Across SNR values')\n","plt.legend(loc='lower right')\n","plt.grid(True)\n","plt.show()\n","path=\"VGG-SNR mod vs  snr\".png\"\n","plt.savefig(path,dpi=300)"],"metadata":{"id":"pJQDUeYAcl6g"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"sc3KHZ0oSW8P"},"execution_count":null,"outputs":[]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.17"}},"nbformat":4,"nbformat_minor":0}